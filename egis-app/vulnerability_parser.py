import csv
from io import StringIO
from datetime import datetime, timedelta
from loguru import logger
import io
import re
import json

class VulnerabilityParser:
    def __init__(self, csv_content, netbox_target_data):
        self.csv_content = csv_content
        self.netbox_target_data = netbox_target_data
        self.netbox_target_map = {target['ip']: target for target in self.netbox_target_data if 'ip' in target}
        logger.debug(f"Initializing vulnerability parser with {len(self.netbox_target_data)} target details")

    def parse(self):
        """
        Parse CSV content into Elasticsearch document format.
        Returns a tuple of (parsed_data, documents)
        """
        logger.info("Parsing CSV vulnerability data")
        csv_text = io.StringIO(self.csv_content.decode('utf-8'))
        reader = csv.DictReader(csv_text)
        csv_rows = list(reader)
        
        # 1. Create base document structure
        document_template = {
            "organization": {
                "id": "",
                "name": "",
                "description": "",
                "primary_contact_name": "",
                "primary_contact_email": "",
                "primary_contact_phone": "",
                "slug": "",
                "contacts": []
            },
            "scanner": {
                "id": "",
                "ip": "",
                "name": "",
                "version": "",
                "os": "",
                "distribution": ""
            },
            "scan": {
                "id": "",
                "name": "",
                "type": "",
                "start_timestamp": "",
                "end_timestamp": "",
                "duration_seconds": "",
                "policy": "",
                "critical_count": 0,
                "high_count": 0,
                "medium_count": 0,
                "low_count": 0,
                "total_vulnerabilities": 0,
                "total_hosts": 0
            },
            "host": {},
            "vulnerability": {},
            "@timestamp": datetime.now().isoformat()
        }
        
        # 2. Extract scanner, scan, and organization info
        self._extract_scanner_and_scan_info(csv_rows, document_template)
        self._extract_organization_info(document_template)
        
        # 3. Build collection of hosts
        hosts_dict = self._build_hosts_collection(csv_rows)
        
        # 4. Process vulnerabilities and update counts
        vulnerabilities = self._process_vulnerabilities(csv_rows, hosts_dict, document_template)
        
        # 5. Create final data structure and documents
        documents = self._create_documents(document_template, hosts_dict, vulnerabilities)
        
        # Convert hosts from dictionary to list for the final parsed data
        hosts = []
        for host_ip, host_data in hosts_dict.items():
            hosts.append(host_data)
        
        parsed_data = {
            "organization": document_template["organization"],
            "scanner": document_template["scanner"],
            "scan": document_template["scan"],
            "hosts": hosts,
            "vulnerabilities": vulnerabilities
        }
        
        scan_info = document_template["scan"]
        logger.info(f"Parsed {scan_info['total_hosts']} hosts with {scan_info['total_vulnerabilities']} vulnerabilities - enriched with Netbox data")
        return parsed_data, documents
    
    def _extract_scanner_and_scan_info(self, csv_rows, document_template):
        """Extract scanner and scan information from plugin ID 19506"""
        scanner_info = document_template["scanner"]
        scan_info = document_template["scan"]
        
        # Find all plugin 19506 rows for scanner and scan info
        for row in csv_rows:
            if row.get("Plugin ID") != "19506":
                continue
        
            plugin_output = row.get("Plugin Output", "")
            
            # Extract scanner info
            if not scanner_info["version"]:
                match = re.search(r"Nessus version : (.+)", plugin_output)
                if match: scanner_info["version"] = match.group(1)

            if not scanner_info["name"]:
                match = re.search(r"Scanner edition used : (.+)", plugin_output)
                if match: scanner_info["name"] = match.group(1)
            
            if not scanner_info["ip"]:
                match = re.search(r"Scanner IP : (.+)", plugin_output)
                if match: scanner_info["ip"] = match.group(1)
                if scanner_info["ip"] and not scanner_info["id"]:
                    scanner_info["id"] = scanner_info["ip"]

            if not scanner_info["os"]:
                match = re.search(r"Scanner OS : (.+)", plugin_output)
                if match: scanner_info["os"] = match.group(1)
            
            if not scanner_info["distribution"]:
                match = re.search(r"Scanner distribution : (.+)", plugin_output)
                if match: scanner_info["distribution"] = match.group(1)
            
            # Extract scan info
            if not scan_info["type"]:
                match = re.search(r"Scan type : (.+)", plugin_output)
                if match: scan_info["type"] = match.group(1)
            
            # Extract scan name
            if not scan_info["name"]:
                match = re.search(r"Scan name : (.+)", plugin_output)
                if match:
                    scan_info["name"] = match.group(1).strip()
                elif scan_info["start_timestamp"]:
                    scan_info["name"] = f"Scan_{datetime.fromisoformat(scan_info['start_timestamp']).strftime('%Y%m%d_%H%M%S')}"
                else:
                    scan_info["name"] = f"Scan_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            
            # Set scan id if not already set
            if not scan_info["id"] and scan_info["name"]:
                scan_info["id"] = scan_info["name"]

            if not scan_info["policy"]:
                match = re.search(r"Scan policy used : (.+)", plugin_output)
                if match: scan_info["policy"] = match.group(1)
            
            # Process scan timestamp and duration
            if not scan_info["start_timestamp"]:
                self._extract_scan_timestamps(plugin_output, scan_info)
    
    def _extract_organization_info(self, document_template):
        """Extract organization info from Netbox data"""
        # Find first available organization info
        org_info = None
        for target in self.netbox_target_data:
            if target.get('organization'):
                org_info = target['organization']
                break
        
        # If found, update the document template
        if org_info:
            document_template["organization"] = {
                "id": str(org_info.get("id", "")),
                "name": org_info.get("name", ""),
                "description": org_info.get("description", ""),
                "primary_contact_name": org_info.get("primary_contact_name", ""),
                "primary_contact_email": org_info.get("primary_contact_email", ""),
                "primary_contact_phone": org_info.get("primary_contact_phone", ""),
                "slug": org_info.get("slug", ""),
                "contacts": org_info.get("contacts", [])
            }
    
    def _extract_scan_timestamps(self, plugin_output, scan_info):
        """Extract scan start timestamp and duration from plugin output"""
        scan_start_match = re.search(r"Scan Start Date : (.+)", plugin_output)
        if scan_start_match:
            try:
                # Parse date format from Nessus
                start_date_str = scan_start_match.group(1)
                
                # Extract the date and time without timezone info
                date_time_match = re.search(r"(\d{4}/\d{1,2}/\d{1,2}\s+\d{1,2}:\d{1,2})", start_date_str)
                if date_time_match:
                    date_time_str = date_time_match.group(1)
                    start_timestamp = datetime.strptime(date_time_str, "%Y/%m/%d %H:%M")
                    
                    # Extract timezone offset
                    timezone_match = re.search(r"UTC ([+-]\d{2}:\d{2})", start_date_str)
                    if timezone_match:
                        offset_str = timezone_match.group(1)
                        hours_offset = int(offset_str.split(':')[0])
                        
                        # Adjust datetime for UTC (subtract the offset)
                        start_timestamp = start_timestamp.replace(tzinfo=None) - timedelta(hours=hours_offset)
                    
                    # Store as ISO8601 string
                    scan_info["start_timestamp"] = self._timestamp_to_iso(int(start_timestamp.timestamp()))
            
            except (ValueError, TypeError) as e:
                logger.warning(f"Failed to parse scan start date: {e}")
                scan_info["start_timestamp"] = ""
        
        # Extract scan duration
        scan_duration_match = re.search(r"Scan duration : (\d+) sec", plugin_output)
        if scan_duration_match:
            try:
                duration_seconds = int(scan_duration_match.group(1))
                scan_info["duration_seconds"] = duration_seconds
                if scan_info["start_timestamp"]:
                    # Calculate end timestamp from start and duration
                    start_time = datetime.fromisoformat(scan_info["start_timestamp"])
                    end_time = start_time + timedelta(seconds=duration_seconds)
                    scan_info["end_timestamp"] = end_time.isoformat()
            except (ValueError, TypeError) as e:
                logger.warning(f"Failed to parse scan duration: {e}")
    
    def _extract_host_os_info(self, plugin_output):
        """Extract OS family, distribution and version from plugin output"""
        os_info = {"os_family": "", "os_distribution": "", "os_version": ""}
        
        os_match = re.search(r"Remote operating system : (.+)", plugin_output)
        if not os_match:
            return os_info
            
        os_text = os_match.group(1)
        
        # Process Windows OS
        if "windows" in os_text.lower():
            os_info["os_family"] = "Windows"
            win_match = re.search(r"Windows ([\w\s\d\.]+)", os_text, re.IGNORECASE)
            if win_match:
                os_info["os_distribution"] = "Windows"
                os_info["os_version"] = win_match.group(1).strip()
        
        # Process Linux OS
        elif "linux" in os_text.lower():
            os_info["os_family"] = "Linux"
            linux_match = re.search(r"(Ubuntu|Debian|CentOS|Red Hat|Fedora|SUSE)[\s\w]*?([\d\.]+)?", os_text, re.IGNORECASE)
            if linux_match:
                os_info["os_distribution"] = linux_match.group(1)
                if linux_match.group(2):
                    os_info["os_version"] = linux_match.group(2)
        
        # Generic OS handling
        else:
            os_info["os_family"] = os_text.split()[0] if os_text else "Unknown"
            os_info["os_distribution"] = os_text
        
        return os_info
    
    def _extract_service_info(self, plugin_name, plugin_output, port):
        """Extract service and version info from plugin output"""
        service = ""
        version = ""
        
        # Check for service detection in plugin name
        if "service detection" in plugin_name.lower():
            service_match = re.search(r"([\w\-]+) Service Detection", plugin_name, re.IGNORECASE)
            if service_match:
                service = service_match.group(1)
        
        # Check common service names
        service_keywords = ["ssh", "ftp", "http", "https", "smtp", "imap", "pop3", "dns", "telnet", "smb"]
        for keyword in service_keywords:
            if keyword in plugin_name.lower() or keyword in plugin_output.lower():
                service = keyword.upper()
                break
        
        # Extract version information
        version_match = re.search(r"version\s*:?\s*([\d\.]+)", plugin_output, re.IGNORECASE)
        if version_match:
            version = version_match.group(1)
        
        # Special case for SSH banner
        if "ssh" in plugin_name.lower() and "banner" in plugin_name.lower():
            banner_match = re.search(r"SSH-\d\.\d-(.+)", plugin_output)
            if banner_match:
                version = banner_match.group(1).strip()
                service = "SSH"
        
        # Special case for HTTP server
        if "http server type and version" in plugin_name.lower():
            server_match = re.search(r"(Apache|nginx|IIS|lighttpd)(?:/|[\s]+)([\d\.]+)", plugin_output, re.IGNORECASE)
            if server_match:
                service = "HTTP"
                version = f"{server_match.group(1)}/{server_match.group(2)}"
        
        return {"service": service, "version": version}
    
    def _build_hosts_collection(self, csv_rows):
        """Build a collection of host data"""
        hosts = {}  # {ip: host_data}
        
        # Extract host IPs from CSV
        for row in csv_rows:
            host_ip = row.get("Host", "")
            if not host_ip or host_ip in hosts:
                continue

            # Create basic host structure
            hosts[host_ip] = {
                "ip": host_ip,
                "dns_name": "",
                "os_family": "",
                "os_distribution": "",
                "os_version": "",
                "device_name": "",
                "device_role": "",
                "site_name": "",
                "rack": "",
                "critical_count": 0,
                "high_count": 0,
                "medium_count": 0,
                "low_count": 0,
                "total_vulnerabilities": 0,
                "open_ports": [],
                "services": {}  # port -> {service, version}
            }
            
            # Add Netbox data if available
            if host_ip in self.netbox_target_map:
                try:
                    netbox_data = self.netbox_target_map[host_ip]
                    
                    # Add hostname from Netbox - use get() to safely access keys
                    hosts[host_ip]['dns_name'] = netbox_data.get('dns_name', '')
                    hosts[host_ip]['device_name'] = netbox_data.get('device_name', '')
                    hosts[host_ip]['device_role'] = netbox_data.get('device_role', '')
                    hosts[host_ip]['site_name'] = netbox_data.get('site_name', '')
                    hosts[host_ip]['rack'] = netbox_data.get('rack', '')
                except Exception as e:
                    logger.warning(f"Error processing Netbox data for host {host_ip}: {e}")
        
        # Extract OS info and services for each host
        for row in csv_rows:
            host_ip = row.get("Host", "")
            if not host_ip or host_ip not in hosts:
                continue
            
            # Extract OS info from plugin 11936 (OS Identification)
            plugin_id = row.get("Plugin ID", "")
            if plugin_id == "11936":
                plugin_output = row.get("Plugin Output", "")
                hosts[host_ip].update(self._extract_host_os_info(plugin_output))
            
            # Extract service information for ports
            port_str = row.get("Port", "")
            if port_str and port_str != "0":
                try:
                    # Convert port to integer
                    port = int(port_str)
                    
                    # Extract service info
                    plugin_name = row.get("Plugin Name", "")
                    plugin_output = row.get("Plugin Output", "")
                    service_info = self._extract_service_info(plugin_name, plugin_output, port)
                    
                    # Check if port already exists in open_ports
                    port_exists = False
                    for port_entry in hosts[host_ip]["open_ports"]:
                        if port_entry["port"] == port:
                            # Update service info if better info is available
                            if service_info["service"] and not port_entry["service"]:
                                port_entry["service"] = service_info["service"]
                            if service_info["version"] and not port_entry["version"]:
                                port_entry["version"] = service_info["version"]
                            port_exists = True
                            break
                    
                    # Add new port entry if it doesn't exist
                    if not port_exists:
                        hosts[host_ip]["open_ports"].append({
                            "port": port,
                            "service": service_info["service"],
                            "version": service_info["version"],
                            "protocol": row.get("Protocol", ""),
                            "has_vulnerabilities": False
                        })
                        
                except (ValueError, TypeError):
                    logger.warning(f"Invalid port value: {port_str} for host {host_ip}")
        
        # Sort open_ports by port number for each host
        for host_ip, host_data in hosts.items():
            host_data["open_ports"] = sorted(host_data["open_ports"], key=lambda x: x["port"])
            
            # Remove legacy services dictionary as it's now incorporated into open_ports
            if "services" in host_data:
                del host_data["services"]
        
        return hosts
    
    def _process_vulnerabilities(self, csv_rows, hosts, document_template):
        """Process vulnerabilities and update counts"""
        vulnerabilities = []  # List of vulnerability records
        
        # Update scan info reference
        scan_info = document_template["scan"]
        
        # Count unique hosts
        scan_info["total_hosts"] = len(hosts)
        
        # Process each vulnerability
        for row in csv_rows:
            host_ip = row.get("Host", "")
            risk = row.get("Risk", "")
            
            # Skip Info and None risks, and hosts not in our collection
            if risk in ["Info", "None"] or host_ip not in hosts:
                continue
            
            vulnerability = {
                "host_ip": host_ip,  # Add reference to host
                "plugin_id": row.get("Plugin ID", ""),
                "name": row.get("Name", ""),
                "severity": risk,
                "port": int(row.get("Port")),
                "protocol": row.get("Protocol", ""),
                "service": "",
                "version": "",
                "cve": row.get("CVE", ""),
                "cvss": {
                    "v2": {
                        "base_score": self._safe_float(row.get("CVSS v2.0 Base Score", "0")),
                        "temporal_score": self._safe_float(row.get("CVSS v2.0 Temporal Score", "0"))
                    },
                    "v3": {
                        "base_score": self._safe_float(row.get("CVSS v3.0 Base Score", "0")),
                        "temporal_score": self._safe_float(row.get("CVSS v3.0 Temporal Score", "0"))
                    },
                    "vpr_score": self._safe_float(row.get("VPR Score", "0"))
                },
                "synopsis": row.get("Synopsis", ""),
                "description": row.get("Description", ""),
                "solution": row.get("Solution", ""),
                "plugin_output": row.get("Plugin Output", ""),
                "risk_factor": row.get("Risk Factor", ""),
                "see_also": row.get("See Also", ""),
                "stig_severity": row.get("STIG Severity", ""),
                "bid": row.get("BID", ""),
                "xref": row.get("XREF", ""),
                "mskb": row.get("MSKB", ""),
                "plugin_publication_date": row.get("Plugin Publication Date", ""),
                "plugin_modification_date": row.get("Plugin Modification Date", ""),
                "exploitable": row.get("Exploitable", "")
            }
            
            # Find port entry and mark as having vulnerabilities
            # Also extract service info if available
            for port_entry in hosts[host_ip]["open_ports"]:
                if port_entry["port"] == vulnerability["port"]:
                    port_entry["has_vulnerabilities"] = True
                    port_entry["severity"] = risk
                    vulnerability["service"] = port_entry["service"]
                    vulnerability["version"] = port_entry["version"]
                    break
            
            # Update vulnerability counts for host
            hosts[host_ip]["total_vulnerabilities"] += 1
            scan_info["total_vulnerabilities"] += 1
            
            if risk == "Critical":
                hosts[host_ip]["critical_count"] += 1
                scan_info["critical_count"] += 1
            elif risk == "High":
                hosts[host_ip]["high_count"] += 1
                scan_info["high_count"] += 1
            elif risk == "Medium":
                hosts[host_ip]["medium_count"] += 1
                scan_info["medium_count"] += 1
            elif risk == "Low":
                hosts[host_ip]["low_count"] += 1
                scan_info["low_count"] += 1
            
            # Add vulnerability to collection
            vulnerabilities.append(vulnerability)
        
        return vulnerabilities
    
    def _create_documents(self, document_template, hosts, vulnerabilities):
        """Create final documents by combining data"""
        documents = []
        
        for vuln in vulnerabilities:
            host_data = hosts[vuln["host_ip"]]
            
            # Determine timestamp: use scan start if available, else now
            scan_start = document_template["scan"].get("start_timestamp")
            if scan_start:
                doc_timestamp = scan_start
            else:
                doc_timestamp = datetime.now().isoformat()
            
            # Create document from template with shallow copies of shared data
            document = {
                "organization": document_template["organization"].copy(),
                "scanner": document_template["scanner"].copy(),
                "scan": document_template["scan"].copy(),
                "host": {
                    "ip": host_data["ip"],
                    "dns_name": host_data["dns_name"],
                    "os_family": host_data["os_family"],
                    "os_distribution": host_data["os_distribution"],
                    "os_version": host_data["os_version"],
                    "device_name": host_data["device_name"],
                    "device_role": host_data["device_role"],
                    "site_name": host_data["site_name"],
                    "rack": host_data["rack"],
                    "critical_count": host_data["critical_count"],
                    "high_count": host_data["high_count"],
                    "medium_count": host_data["medium_count"],
                    "low_count": host_data["low_count"],
                    "total_vulnerabilities": host_data["total_vulnerabilities"],
                    "open_ports": host_data["open_ports"]
                },
                "vulnerability": vuln.copy(),
                "@timestamp": doc_timestamp
            }
            # Remove host_ip from vulnerability as it's redundant
            if "host_ip" in document["vulnerability"]:
                del document["vulnerability"]["host_ip"]
            
            documents.append(document)
        
        return documents
    
    def to_elasticsearch_json(self, parsed_data):
        """
        Convert the Elasticsearch documents to a JSON string.
        """
        return json.dumps(parsed_data, indent=2, default=str)
    
    def _safe_float(self, value):
        """Safely convert string to float"""
        try:
            return float(value)
        except (ValueError, TypeError):
            return 0.0
    
    def _timestamp_to_iso(self, timestamp):
        """Convert Unix timestamp to ISO8601 string format"""
        if not timestamp:
            return ""
        try:
            return datetime.fromtimestamp(timestamp).isoformat()
        except (ValueError, TypeError, OverflowError):
            return ""
